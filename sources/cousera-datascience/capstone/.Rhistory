table(lda.class, Direction.2005)
qda.fit=qda(Direction ~ Lag1+Lag2,data=Smarket ,subset=train)
qda.fit
qda.class=predict(qda.fit,Smarket.2005)$class
table(qda.class, Direction.2005)
mean(qda.class==Direction.2005)
library(class)
train.X=cbind(Lag1 ,Lag2)[train ,]
test.X=cbind(Lag1,Lag2)[!train ,]
train.Direction =Direction [train]
train.X=cbind(Smarket$Lag1, Smarket$Lag2)[train ,]
test.X=cbind(Smarket$Lag1,Smarket$Lag2)[!train ,]
train.Direction =Direction [train]
train.Direction = Smarket$Direction [train]
set.seed(1)
knn.pred=knn(train.X,test.X,train.Direction ,k=1)
table(knn.pred,Direction.2005)
knn.pred=knn(train.X,test.X,train.Direction, k=3)
table(knn.pred,Direction.2005)
dim(Caravan)
standardized.X=scale(Caravan [,-86])
var(Caravan [,1])
var(standardized.X[,1])
test=1:1000
train.X=standardized.X[-test ,]
test.X=standardized.X[test ,]
train.Y=Purchase [-test]
test.Y=Purchase [test]
train.Y=Caravan$Purchase [-test]
test.Y=Caravan$Purchase [test]
set.seed(1)
knn.pred=knn(train.X,test.X,train.Y,k=1)
mean(test.Y!=knn.pred)
mean(test.Y!="No")
table(knn.pred,test.Y)
glm.fit=glm(Purchase~.,data=Caravan ,family=binomial, subset=-test)
glm.probs=predict(glm.fit,Caravan[test ,],type="response ")
glm.pred=rep("No",1000)
glm.probs=predict(glm.fit,Caravan[test ,],type="response ")
glm.probs=predict(glm.fit,Caravan[test ,],type="response")
glm.pred=rep("No",1000)
glm.pred[glm.probs >.5]="Yes"
table(glm.pred,test.Y)
glm.pred=rep("No",1000)
glm.pred[glm.probs >.25]="Yes"
table(glm.pred,test.Y)
source('C:/github/xunilrj-sandbox/sources/books/AnIntroductiontoStatisticalLearning/chapter04.lab.r')
library(ISLR)
set.seed(1)
train=sample (392,196)
lm.fit=lm(mpg~horsepower ,data=Auto,subset=train)
mean((Auto$mpg - predict(lm.fit, Auto))[-train]^2)
library(boot)
glm.fit=glm(mpg∼horsepower ,data=Auto)
cv.err=cv.glm(Auto ,glm.fit)
cv.err$delta
cv.error=rep(0,5)
for (i in 1:5){
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10){
glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10){
glm.fit=glm(mpg ~ poly(horsepower ,i),data=Auto)
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
alpha.fn=function (data,index){
X=data$X[index]
Y=data$Y[index]
return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))
}
alpha.fn(Portfolio ,1:100)
set.seed(1)
alpha.fn(Portfolio ,sample (100,100, replace=T))
boot(Portfolio, alpha.fn, R=1000)
boot.fn=function (data ,index) return(coef(lm(mpg ~ horsepower ,data=data,subset=index)))
boot.fn(Auto ,1:392)
set.seed(1)
boot.fn(Auto ,sample (392,392, replace=T))
boot(Auto ,boot.fn, 1000)
boot.fn=function (data ,index) coefficients(lm(mpg~horsepower +I(horsepower ^2),data=data ,                   subset=index))
set.seed(1)
boot(Auto ,boot.fn,1000)
Hitters=na.omit(Hitters)
library(leaps)
install.packages("leaps")
library(leaps)
regfit.full=regsubsets (Salary~.,Hitters)
summary(regfit.full)
plot(reg.summary$rss ,xlab="Number of Variables ",ylab="RSS",       type="l")
regfit.full=regsubsets (Salary~.,data=Hitters ,nvmax=19)
reg.summary=summary(regfit.full)
par(mfrow=c(2,2))
plot(reg.summary$rss ,xlab="Number of Variables ",ylab="RSS",       type="l")
plot(reg.summary$adjr2 ,xlab="Number of Variables ",       ylab="Adjusted RSq",type="l")
points(11,reg.summary$adjr2[11], col="red",cex=2,pch=20)
plot(regfit.full,scale="r2")
plot(regfit.full,scale="adjr2")
plot(regfit.full,scale="Cp")
plot(regfit.full,scale="bic")
plot(regfit.full,scale="r2")
plot.regsubsets (regfit.full,scale="r2")
regfit.fwd=regsubsets (Salary~.,data=Hitters ,nvmax=19,                       method="forward ")
regfit.fwd=regsubsets (Salary~.,data=Hitters ,nvmax=19, method="forward")
summary(regfit.fwd)
regfit.bwd=regsubsets (Salary~.,data=Hitters ,nvmax=19, method="backward")
summary(regfit.bwd)
k=10
set.seed(1)
folds=sample(1:k,nrow(Hitters),replace=TRUE)
cv.errors=matrix(NA,k,19, dimnames =list(NULL , paste(1:19)))
for(j in 1:k){
best.fit=regsubsets (Salary∼.,data=Hitters[folds!=j,],nvmax=19)
for(i in 1:19){
pred=predict(best.fit ,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2)
}
}
for(j in 1:k){
best.fit=regsubsets (Salary~.,data=Hitters[folds!=j,],nvmax=19)
for(i in 1:19){
pred=predict(best.fit ,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2)
}
}
predict.regsubsets =function (object ,newdata ,id,...){
form=as.formula(object$call [[2]])
mat=model.matrix(form,newdata)
coefi=coef(object ,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
for(j in 1:k){
best.fit=regsubsets (Salary~.,data=Hitters[folds!=j,],nvmax=19)
for(i in 1:19){
pred=predict(best.fit ,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors ,2,mean)
mean.cv.errors
par(mfrow=c(1,1))
plot(mean.cv.errors ,type=’b’)
plot(mean.cv.errors ,type="b")
sample(1:k,nrow(Hitters),replace=TRUE)
?sample
sample(1:10)
sample(1:10, n = 2)
sample(1:10, 2)
sample(1:10, 2)
sample(1:10, 20)
sample(1:10, 20, replace = TRUE)
hist(sample(1:10, 20, replace = TRUE))
hist(sample(1:10, 200, replace = TRUE))
hist(sample(1:10, 200, replace = TRUE))
hist(sample(1:10, 200, replace = TRUE))
hist(sample(1:10, 20, replace = TRUE), breaks = 10)
hist(sample(1:10, 20, replace = TRUE), breaks = 11)
hist(sample(1:10, 20, replace = TRUE), breaks = 12)
hist(sample(1:10, 20, replace = TRUE), breaks = 5)
hist(sample(1:10, 20, replace = TRUE), breaks = 5)
hist(sample(1:10, 200, replace = TRUE), breaks = 5)
cv.errors
plot(mean.cv.errors ,type="b")
install.packages("glmnet")
y
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
y
library(glmnet)
grid=10^seq(10,-2, length =100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.mod=glmnet(x[train ,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
set.seed(1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test ,])
mean((lasso.pred-y.test)^2)
y.test=y[test]
mean((lasso.pred-y.test)^2)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.coef
library(pls)
set.seed(2)
pcr.fit=pcr(Salary∼., data=Hitters ,scale=TRUE, validation ="CV")
install.packages("pls")
library(pls)
set.seed(2)
pcr.fit=pcr(Salary~., data=Hitters ,scale=TRUE, validation ="CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type="MSEP")
summary(pcr.fit)
set.seed(1)
pcr.fit=pcr(Salary~., data=Hitters ,subset=train ,scale=TRUE,validation ="CV")
validationplot(pcr.fit,val.type="MSEP")
pcr.pred=predict(pcr.fit ,x[test ,],ncomp=7)
mean((pcr.pred-y.test)^2)
pcr.fit=pcr(y∼x,scale=TRUE,ncomp=7)
pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
summary(pcr.fit)
set.seed(1)
pls.fit=plsr(Salary~., data=Hitters ,subset=train ,scale=TRUE ,validation ="CV")
summary(pls.fit)
pls.pred=predict(pls.fit ,x[test ,],ncomp=2)
mean((pls.pred-y.test)^2)
pls.fit=plsr(Salary∼., data=Hitters ,scale=TRUE,ncomp=2)
pls.fit=plsr(Salary~., data=Hitters ,scale=TRUE,ncomp=2)
summary(pls.fit)
shiny::runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
data("iris")
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
data("Iris")
runApp('C:/github/shinyappcluster/Clustering')
?data
a <- "iris"
data(a)
data(list=a)
runApp('C:/github/shinyappcluster/Clustering')
names(data("iris"))
data("iris")
str(data("iris"))
colnames(data("iris"))
colnames(iris)
attach(data("iris"))
attach(data(iris))
iris <- data(iris)
colnames(iris)
d <- data(iris)
iris
get("iris)")
get("iris")
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
iris
iris["Setal.Width"]
iris["Sepal.Width"]
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
iris["Sepal.Width"]
iris["Sepal.Width",]
iris[,"Sepal.Width"]
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
kmeans(iris, 3)
knn(iris)
library(class)
knn
knn(iris)
knn(iris, iris[-1,])
iris[-1,]
iris
iris[1:149,]
iris[150,]
knn(iris, iris[150,])
knn(iris[,c("Sepal.Length")], iris[150,c("Sepal.Length")], iris[,"Species"] )
knn(iris[,c("Sepal.Length")], iris[150,c("Sepal.Length")], iris[,"Species"], 3 )
knn(iris[,c("Sepal.Length")], iris[,c("Sepal.Length")], iris[,"Species"], 3 )
knn(iris[,c("Sepal.Length")], iris[,c("Sepal.Length")], iris[,"Species"] )
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
iris[,c("Species")]
iris[,c("Species")]$levels
unique(iris[,c("Species")])
runApp('C:/github/shinyappcluster/Clustering')
rep(19, 2)
rep(19, length(c(1,2,3))
)
runApp('C:/github/shinyappcluster/Clustering')
pallette(rainbow(6))
palette(raibow(6))
palette(6)
?knn
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
colorRampPalette(c("red", "green"))(5)
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
?knn
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
library(ggplot2)
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
ggplot(iris,aes(x=Sepal.Width,y=Sepal.Length))
ggplot(iris,aes(x=Sepal.Width,y=Sepal.Length)) +geom_point()
ggplot(iris,aes(x=iris[,"Sepal.Width"],y=Sepal.Length)) +geom_point()
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
plot_ly(df, x = ~x,y = ~y)
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
data(list="Orange")
get("Orange")
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
data(airquality)
get(airquality)
get("airquality")
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
install.packages("rsconnect")
shiny::runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
runApp('C:/github/shinyappcluster/Clustering')
library(rsconnect)
install.packages("rsconnect")
getOption("repo")
getOptions("repo")
getOption("repos")
install.packages("rsconnect")
install.packages("C:/Users/xunil/Downloads/rsconnect_0.7.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/xunil/Downloads/rmarkdown_1.4.zip", repos = NULL, type = "win.binary")
library(plotly)
library('MASS')
simulation.g1 <- mvrnorm(n = 1000, c(0,0), diag(2))
simulation.g2 <- mvrnorm(n = 1000, c(-3,-3), diag(c(0.3,10)))
simulation <- rbind(simulation.g1, simulation.g2)
simulation <- data.frame(x = simulation[,1], y = simulation[,2])
fit <- kmeans(simulation, 5)
plot(simulation$x, simulation$y, col = fit$clusters)
View(simulation)
plot(simulation$x, simulation$y)
fit$cluster
plot(simulation$x, simulation$y, col = fit$cluster)
d <- dist(simulation, method = "euclidean")
fit <- hclust(d, method="ward")
cutree(fit, k=5)
library(mclust)
install.packages("mclust")
Mclust(simulation)
library(mclust)
Mclust(simulation)
fit <- mclust(simulation)
fit <- Mclust(simulation)
plot(simulation$x, simulation$y, col = Mclust(simulation, G=2)$classification)
plot(simulation$x, simulation$y, col = Mclust(simulation, G=2)$classification)
?Mclust
?kmeans
?hclust
source('C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone/createCorpus.R')
crateCorpus("temp/enustweets%03d.%s", 0)
setwd("C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone")
crateCorpus("temp/enustweets%03d.%s", 0)
source("download.data.R")
source("SplitArray.R")
library(sampling)
library(tm)
library(SnowballC)
crateCorpus("temp/enustweets%03d.%s", 0)
for (i in 0:(n-1) ) {
crateCorpus("temp/enustweets%03d.%s", i)
}
n<- 100
for (i in 0:(n-1) ) {
crateCorpus("temp/enustweets%03d.%s", i)
}
source('C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone/createCorpus.R')
library("parallel")
library("foreach")
library("doParallel")
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl, cores = detectCores() - 1)
foreach(i = 1:(n-1)) %dopar% {
try({
crateCorpus("temp/enustweets%03d.%s", i)
})
}
stopCluster(cl)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl, cores = detectCores() - 1)
foreach(i = 1:(n-1), .packages = c("tm","SnowballC")) %dopar% {
try({
crateCorpus("temp/enustweets%03d.%s", i)
})
}
stopCluster(cl
source("generateTDM.R")
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl, cores = detectCores() - 1)
foreach(i = 1:(n-1)) %dopar% {
try({
generateTDM("temp/enustweets%03d.%s", i)
})
}
stopCluster(cl)
source('C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone/generateTDM.R')
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl, cores = detectCores() - 1)
foreach(i = 1:(n-1)) %dopar% {
try({
generateTDM("temp/enustweets%03d.%s", i)
})
}
stopCluster(cl)
source('C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone/generateDTM.R')
source('C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone/generateDTM.R')
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl, cores = detectCores() - 1)
foreach(i = 1:(n-1)) %dopar% {
try({
generateDTM("temp/enustweets%03d.%s", i)
})
}
stopCluster(cl)
lines = readLines("final/en_US/en_US.news.txt", encoding = "UTF-8")
splitIn(lines, 100, "temp/enusnews%03d.txt")
lines = readLines("final/en_US/en_US.news.txt", encoding = "UTF-8")
?readLines
lines = readLines("final/en_US/en_US.news.txt")
lines = readLines("final/en_US/en_US.news.txt", skipNul = TRUE)
setwd("C:/github/xunilrj-sandbox/sources/cousera-datascience/capstone")
lines = readLines("final/en_US/en_US.news.txt", skipNul = TRUE)
